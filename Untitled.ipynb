{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "from prototxt_basic import *\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parser = argparse.ArgumentParser(description='Convert MXNet jason to caffe prototxt')\n",
    "\n",
    "parser.add_argument('--mx-json', type=str, default='mobilenet025-ssd-224-symbol.json')\n",
    "\n",
    "parser.add_argument('--cf-prototxt', type=str, default='cvt_test.prototxt')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mobilenet025-ssd-224-symbol.json') as json_file:\n",
    "    jdata = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, \top:null                , name:data                           -> data\n",
      "2, \top:Convolution         , name:conv_1_conv2d                  -> conv_1_conv2d\n",
      "use shared weight -> data\n",
      "test\n",
      "7, \top:BatchNorm           , name:conv_1_batchnorm               -> conv_1_batchnorm\n",
      "use shared weight -> conv_1_conv2d\n",
      "8, \top:Activation          , name:conv_1_relu                    -> conv_1_relu\n",
      "use shared weight -> conv_1_batchnorm\n",
      "10, \top:Convolution         , name:conv_2_dw_conv2d               -> conv_2_dw_conv2d\n",
      "use shared weight -> conv_1_relu\n",
      "test\n",
      "15, \top:BatchNorm           , name:conv_2_dw_batchnorm            -> conv_2_dw_batchnorm\n",
      "use shared weight -> conv_2_dw_conv2d\n",
      "16, \top:Activation          , name:conv_2_dw_relu                 -> conv_2_dw_relu\n",
      "use shared weight -> conv_2_dw_batchnorm\n",
      "18, \top:Convolution         , name:conv_2_conv2d                  -> conv_2_conv2d\n",
      "use shared weight -> conv_2_dw_relu\n",
      "test\n",
      "23, \top:BatchNorm           , name:conv_2_batchnorm               -> conv_2_batchnorm\n",
      "use shared weight -> conv_2_conv2d\n",
      "24, \top:Activation          , name:conv_2_relu                    -> conv_2_relu\n",
      "use shared weight -> conv_2_batchnorm\n",
      "26, \top:Convolution         , name:conv_3_dw_conv2d               -> conv_3_dw_conv2d\n",
      "use shared weight -> conv_2_relu\n",
      "test\n",
      "31, \top:BatchNorm           , name:conv_3_dw_batchnorm            -> conv_3_dw_batchnorm\n",
      "use shared weight -> conv_3_dw_conv2d\n",
      "32, \top:Activation          , name:conv_3_dw_relu                 -> conv_3_dw_relu\n",
      "use shared weight -> conv_3_dw_batchnorm\n",
      "34, \top:Convolution         , name:conv_3_conv2d                  -> conv_3_conv2d\n",
      "use shared weight -> conv_3_dw_relu\n",
      "test\n",
      "39, \top:BatchNorm           , name:conv_3_batchnorm               -> conv_3_batchnorm\n",
      "use shared weight -> conv_3_conv2d\n",
      "40, \top:Activation          , name:conv_3_relu                    -> conv_3_relu\n",
      "use shared weight -> conv_3_batchnorm\n",
      "42, \top:Convolution         , name:conv_4_dw_conv2d               -> conv_4_dw_conv2d\n",
      "use shared weight -> conv_3_relu\n",
      "test\n",
      "47, \top:BatchNorm           , name:conv_4_dw_batchnorm            -> conv_4_dw_batchnorm\n",
      "use shared weight -> conv_4_dw_conv2d\n",
      "48, \top:Activation          , name:conv_4_dw_relu                 -> conv_4_dw_relu\n",
      "use shared weight -> conv_4_dw_batchnorm\n",
      "50, \top:Convolution         , name:conv_4_conv2d                  -> conv_4_conv2d\n",
      "use shared weight -> conv_4_dw_relu\n",
      "test\n",
      "55, \top:BatchNorm           , name:conv_4_batchnorm               -> conv_4_batchnorm\n",
      "use shared weight -> conv_4_conv2d\n",
      "56, \top:Activation          , name:conv_4_relu                    -> conv_4_relu\n",
      "use shared weight -> conv_4_batchnorm\n",
      "58, \top:Convolution         , name:conv_5_dw_conv2d               -> conv_5_dw_conv2d\n",
      "use shared weight -> conv_4_relu\n",
      "test\n",
      "63, \top:BatchNorm           , name:conv_5_dw_batchnorm            -> conv_5_dw_batchnorm\n",
      "use shared weight -> conv_5_dw_conv2d\n",
      "64, \top:Activation          , name:conv_5_dw_relu                 -> conv_5_dw_relu\n",
      "use shared weight -> conv_5_dw_batchnorm\n",
      "66, \top:Convolution         , name:conv_5_conv2d                  -> conv_5_conv2d\n",
      "use shared weight -> conv_5_dw_relu\n",
      "test\n",
      "71, \top:BatchNorm           , name:conv_5_batchnorm               -> conv_5_batchnorm\n",
      "use shared weight -> conv_5_conv2d\n",
      "72, \top:Activation          , name:conv_5_relu                    -> conv_5_relu\n",
      "use shared weight -> conv_5_batchnorm\n",
      "74, \top:Convolution         , name:conv_6_dw_conv2d               -> conv_6_dw_conv2d\n",
      "use shared weight -> conv_5_relu\n",
      "test\n",
      "79, \top:BatchNorm           , name:conv_6_dw_batchnorm            -> conv_6_dw_batchnorm\n",
      "use shared weight -> conv_6_dw_conv2d\n",
      "80, \top:Activation          , name:conv_6_dw_relu                 -> conv_6_dw_relu\n",
      "use shared weight -> conv_6_dw_batchnorm\n",
      "82, \top:Convolution         , name:conv_6_conv2d                  -> conv_6_conv2d\n",
      "use shared weight -> conv_6_dw_relu\n",
      "test\n",
      "87, \top:BatchNorm           , name:conv_6_batchnorm               -> conv_6_batchnorm\n",
      "use shared weight -> conv_6_conv2d\n",
      "88, \top:Activation          , name:conv_6_relu                    -> conv_6_relu\n",
      "use shared weight -> conv_6_batchnorm\n",
      "90, \top:Convolution         , name:conv_7_dw_conv2d               -> conv_7_dw_conv2d\n",
      "use shared weight -> conv_6_relu\n",
      "test\n",
      "95, \top:BatchNorm           , name:conv_7_dw_batchnorm            -> conv_7_dw_batchnorm\n",
      "use shared weight -> conv_7_dw_conv2d\n",
      "96, \top:Activation          , name:conv_7_dw_relu                 -> conv_7_dw_relu\n",
      "use shared weight -> conv_7_dw_batchnorm\n",
      "98, \top:Convolution         , name:conv_7_conv2d                  -> conv_7_conv2d\n",
      "use shared weight -> conv_7_dw_relu\n",
      "test\n",
      "103, \top:BatchNorm           , name:conv_7_batchnorm               -> conv_7_batchnorm\n",
      "use shared weight -> conv_7_conv2d\n",
      "104, \top:Activation          , name:conv_7_relu                    -> conv_7_relu\n",
      "use shared weight -> conv_7_batchnorm\n",
      "106, \top:Convolution         , name:conv_8_dw_conv2d               -> conv_8_dw_conv2d\n",
      "use shared weight -> conv_7_relu\n",
      "test\n",
      "111, \top:BatchNorm           , name:conv_8_dw_batchnorm            -> conv_8_dw_batchnorm\n",
      "use shared weight -> conv_8_dw_conv2d\n",
      "112, \top:Activation          , name:conv_8_dw_relu                 -> conv_8_dw_relu\n",
      "use shared weight -> conv_8_dw_batchnorm\n",
      "114, \top:Convolution         , name:conv_8_conv2d                  -> conv_8_conv2d\n",
      "use shared weight -> conv_8_dw_relu\n",
      "test\n",
      "119, \top:BatchNorm           , name:conv_8_batchnorm               -> conv_8_batchnorm\n",
      "use shared weight -> conv_8_conv2d\n",
      "120, \top:Activation          , name:conv_8_relu                    -> conv_8_relu\n",
      "use shared weight -> conv_8_batchnorm\n",
      "122, \top:Convolution         , name:conv_9_dw_conv2d               -> conv_9_dw_conv2d\n",
      "use shared weight -> conv_8_relu\n",
      "test\n",
      "127, \top:BatchNorm           , name:conv_9_dw_batchnorm            -> conv_9_dw_batchnorm\n",
      "use shared weight -> conv_9_dw_conv2d\n",
      "128, \top:Activation          , name:conv_9_dw_relu                 -> conv_9_dw_relu\n",
      "use shared weight -> conv_9_dw_batchnorm\n",
      "130, \top:Convolution         , name:conv_9_conv2d                  -> conv_9_conv2d\n",
      "use shared weight -> conv_9_dw_relu\n",
      "test\n",
      "135, \top:BatchNorm           , name:conv_9_batchnorm               -> conv_9_batchnorm\n",
      "use shared weight -> conv_9_conv2d\n",
      "136, \top:Activation          , name:conv_9_relu                    -> conv_9_relu\n",
      "use shared weight -> conv_9_batchnorm\n",
      "138, \top:Convolution         , name:conv_10_dw_conv2d              -> conv_10_dw_conv2d\n",
      "use shared weight -> conv_9_relu\n",
      "test\n",
      "143, \top:BatchNorm           , name:conv_10_dw_batchnorm           -> conv_10_dw_batchnorm\n",
      "use shared weight -> conv_10_dw_conv2d\n",
      "144, \top:Activation          , name:conv_10_dw_relu                -> conv_10_dw_relu\n",
      "use shared weight -> conv_10_dw_batchnorm\n",
      "146, \top:Convolution         , name:conv_10_conv2d                 -> conv_10_conv2d\n",
      "use shared weight -> conv_10_dw_relu\n",
      "test\n",
      "151, \top:BatchNorm           , name:conv_10_batchnorm              -> conv_10_batchnorm\n",
      "use shared weight -> conv_10_conv2d\n",
      "152, \top:Activation          , name:conv_10_relu                   -> conv_10_relu\n",
      "use shared weight -> conv_10_batchnorm\n",
      "154, \top:Convolution         , name:conv_11_dw_conv2d              -> conv_11_dw_conv2d\n",
      "use shared weight -> conv_10_relu\n",
      "test\n",
      "159, \top:BatchNorm           , name:conv_11_dw_batchnorm           -> conv_11_dw_batchnorm\n",
      "use shared weight -> conv_11_dw_conv2d\n",
      "160, \top:Activation          , name:conv_11_dw_relu                -> conv_11_dw_relu\n",
      "use shared weight -> conv_11_dw_batchnorm\n",
      "162, \top:Convolution         , name:conv_11_conv2d                 -> conv_11_conv2d\n",
      "use shared weight -> conv_11_dw_relu\n",
      "test\n",
      "167, \top:BatchNorm           , name:conv_11_batchnorm              -> conv_11_batchnorm\n",
      "use shared weight -> conv_11_conv2d\n",
      "168, \top:Activation          , name:conv_11_relu                   -> conv_11_relu\n",
      "use shared weight -> conv_11_batchnorm\n",
      "170, \top:Convolution         , name:conv_12_dw_conv2d              -> conv_12_dw_conv2d\n",
      "use shared weight -> conv_11_relu\n",
      "test\n",
      "175, \top:BatchNorm           , name:conv_12_dw_batchnorm           -> conv_12_dw_batchnorm\n",
      "use shared weight -> conv_12_dw_conv2d\n",
      "176, \top:Activation          , name:conv_12_dw_relu                -> conv_12_dw_relu\n",
      "use shared weight -> conv_12_dw_batchnorm\n",
      "178, \top:Convolution         , name:conv_12_conv2d                 -> conv_12_conv2d\n",
      "use shared weight -> conv_12_dw_relu\n",
      "test\n",
      "183, \top:BatchNorm           , name:conv_12_batchnorm              -> conv_12_batchnorm\n",
      "use shared weight -> conv_12_conv2d\n",
      "184, \top:Activation          , name:conv_12_relu                   -> conv_12_relu\n",
      "use shared weight -> conv_12_batchnorm\n",
      "187, \top:Convolution         , name:conv_12_relu_cls_pred_conv     -> conv_12_relu_cls_pred_conv\n",
      "use shared weight -> conv_12_relu\n",
      "test\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'no_bias'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bc584af0e7cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'use shared weight -> %s'\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'share'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mwrite_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprototxt_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/niekai/PycharmProjects/MobileNet-SSD/prototxt_basic.py\u001b[0m in \u001b[0;36mwrite_node\u001b[0;34m(txt_file, info)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'op'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Convolution'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'op'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ChannelwiseConvolution'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mChannelwiseConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/niekai/PycharmProjects/MobileNet-SSD/prototxt_basic.py\u001b[0m in \u001b[0;36mConvolution\u001b[0;34m(txt_file, info)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mConvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'no_bias'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'True'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mbias_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'false'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'no_bias'"
     ]
    }
   ],
   "source": [
    "with open('test_cvt.prototxt', \"w\") as prototxt_file:\n",
    "    for i_node in range(0, len(jdata['nodes'])):\n",
    "        node_i = jdata['nodes'][i_node]\n",
    "        if str(node_i['op']) == 'null' and str(node_i['name']) != 'data':\n",
    "            continue\n",
    "        print('{}, \\top:{}, name:{} -> {}'.format(i_node,node_i['op'].ljust(20),\n",
    "                                                node_i['name'].ljust(30),\n",
    "                                                node_i['name']).ljust(20))\n",
    "        info = node_i\n",
    "        info['top'] = info['name']\n",
    "        info['bottom'] = []\n",
    "        info['params'] = []\n",
    "        for input_idx_i in node_i['inputs']:\n",
    "            input_i = jdata['nodes'][input_idx_i[0]]\n",
    "            if str(input_i['op']) != 'null' or (str(input_i['name']) == 'data'):\n",
    "                info['bottom'].append(str(input_i['name']))\n",
    "            if str(input_i['op']) == 'null':\n",
    "                info['params'].append(str(input_i['name']))\n",
    "            if not str(input_i['name']).startswith(str(node_i['name'])):\n",
    "                print('use shared weight -> %s'% str(input_i['name']))\n",
    "                info['share'] = True\n",
    "        write_node(prototxt_file, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'attr': {u'kernel': u'(3, 3)',\n",
       "  u'num_filter': u'8',\n",
       "  u'pad': u'(1, 1)',\n",
       "  u'stride': u'(1, 1)'},\n",
       " 'bottom': ['conv_12_relu'],\n",
       " u'inputs': [[184, 0, 0], [185, 0, 0], [186, 0, 0]],\n",
       " u'name': u'conv_12_relu_cls_pred_conv',\n",
       " u'op': u'Convolution',\n",
       " 'params': ['conv_12_relu_cls_pred_conv_weight',\n",
       "  'conv_12_relu_cls_pred_conv_bias'],\n",
       " 'share': True,\n",
       " 'top': u'conv_12_relu_cls_pred_conv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'True'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info['attr']['no_bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
